<!DOCTYPE html>
 <html>
 	<head>
 		<meta charset="utf-8">
 		<meta http-equiv="X-UA-Compatible" content="IE=edge">
 		<title>Critical Critters Usability Evaluation</title>
 		<meta name="description" content="A usability report for COMP210" />
 		<meta name="author" content="Alcwyn Parker" />
 		<meta name="HandheldFriendly" content="true" />
 		<meta name="MobileOptimized" content="320" />

    <!-- Use maximum-scale and user-scalable at your own risk. It disables pinch/zoom. Think about usability/accessibility before including.-->
 		<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
 		<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
 		<link rel="stylesheet" type="text/css" href="css/main.css">
    <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
 	</head>
 	<body>

    <div class="main-container">
      <header>
        <h1>Critical Critters</h1>
        <h2 style="font-style: italic"><i>Playability Evaluation</i></h2>
      </header>
      <div class="content">
        <aside>
          <nav>
            <ul>
              <li><a href="index.html">Introduction </a></li>
              <li><a class="selected" href="methods.html">Methods </a></li>
              <li><a href="results.html">Results </a></li>
              <li><a href="discussion.html">Discussion </a></li>
              <li><a href="conclusion.html">Conclusion </a></li>
            </ul>
          </nav>
        </aside>

        <section>
		  <h2>Heuristic Evaluation</h2>
			<h3>Process</h3>
			<p>The heuristic evaluation was conducted remotely with computing and game development university students, henceforth questionably entitled 'the experts', in separate locations independently to each other. The observer, also questionably entitled 'game designer', monitored them through gameplay and text-based chat, and offered commentary in response to questions. The heuristics to be evaluated were distributed on a digital Word document, which was filled and sent back upon completion.</p>
			<p>The sample was chosen based on the limited population available in the short time. Based on an implication that they would have greater expertise in evaluation techniques, the selected students were development students who had attended UX evaluation classes. These were all programmers. However, a further study could improve the level of expertise by employing a more diverse range of game designers, artists and similar creative leads - this could offer significantly more expertise in the artistic and design-oriented heuristics, such as humor and screen layout.</p>
			<p>Each evaluation had between one and two players in the actual game. The lack of players may have negatively impacted the simulation of domains such as player communication and balance, but was adequate for the time available. In a future evaluation, a specific player count could be established to reflect the standard online multiplayer experience.</p>
			<p>Each heuristic was assigned a severity rating of between 1 and 5. 1 was of minimal but noteworthy concern, whilst 5 was of highest priority. This was to help collate and prioritise the discovered issues in combination with the results of the Player Evaluation. Issues in each heuristic domain will be tallied, and the domains with the highest scores will quality as the Top 3 Issues for further discussion. This technique is chosen to reduce the number of these qualitative samples to a manageable amount, so they can be reviewed and discussed in good time.</p>
			<h3>Selection of heuristics</h3>
			<p>The following heuristics were selected based off of H. Desurvire and C. Wiberg's findings in 2009 [1].</p>
			<ul>
				<li>Enduring Play <i>(to identify hindrances to player enjoyment when interacting with the game)</i></li>
				<li>Variety of Players and Game Styles <i>(to explore differences in balance and abilities between the two characters)</i></li>
				<li>Player’s Perception of Control <i>(to ensure that the game's goal of fast-paced, tight controls is satisfied)</i></li>
				<li>Coolness/Entertainment <i>(to test the popularity of the game's unique quirks, such as rainbows)</i></li>
				<li>Humor <i>(to test the popularity and appropriateness of the game's humourous, but potentially dark elements, such as the self-destructing pigeon)</i></li>
				<li>Immersion <i>(to ensure the game world in convincing)</i></li>
				<li>Documentation/Tutorial <i>(to test the severity of the lack of a tutorial in game, whether controls are easily self-taught)</i></li>
				<li>Status and Score <i>(to ensure the score is intuitively displayed and simple to understand)</i></li>
				<li>Game Provides Feedback <i>(to ensure the feedback provided by the game is satisfying and does not impose - e.g. the regular camera shakes, lack of sound effects)</i></li>
				<li>Burden On Player <i>(to measure potential frustration in controlling the game characters)</i></li>
				<li>Screen Layout <i>(to ensure the information on the screen, such as the static charge bar or healthbars, are in a sensible place with a sensible size)</i></u></li>
				<li>Error Prevention <i>(to identify glitches and hindrances in the game)</i></li>
			</ul>
			<p>Additionally, due to the intrinsic differences between single-player and multi-player games such as: the presence of player interactions, the number of players, potential griefing opportunities and more, the following heuristics were sourced from D. Pinelle et. al, 2009 [2] which focuses on these multi-player heuristics in particular.</p>
			<ul>
				<li>Communication <i>(to ensure the players can communicate with each other, and that the text chat feature is adequate)</i></li>
				<li>Awareness <i>(to ensure that the players are easy to find, or that the rainbows are helpful in finding them, or that there could be more ways to find players)</i></li>
				<li>Game play balance <i>(finally, to ensure that the pigeon and bunny characters are both well-balanced and not overpowered)</i></li>
			</ul>
			<h3>Sources</h3>
			<i>1.	H. Desurvire and C. Wiberg, “Game Usability Heuristics (PLAY) for Evaluating and Designing Better Games: The Next Iteration” in OCSC '09 Proceedings of the 3d International Conference on Online Communities and Social Computing, San Diego, CA, 19-24 July 2009, pp. 557-566</i><br/>
			<i>2.	D. Pinelle, N. Wong, T. Stach, and C. Gutwin. 2009. “Usability heuristics for networked multiplayer games” in Proceedings of the ACM 2009 international conference on Supporting group work (GROUP '09). ACM, New York, NY, USA, 169-178.</i>
		</section>
		<section>
			<h2>Player Evaluation</h2>
			<h3>Goals and preparation</h3>
			<p>The primary goals of the player evaluation were to identify the intuitiveness and discoverability of the game controls, character preferences, and general strengths/flaws. Due to a short time scale, an online questionnaire was selected as the methodology. This would allow quantitative and qualitative results to be automatically recorded into the system, eliminating a need to collate or transcribe information, and would be most efficient for the player's time.</p>
			<p>The player evaluation took additionally collected screen recordings. Players were aware of the recordings after being selected and all gave permission. The recordings were intended to be used to collect timestamps for player character changes (to associate character playtime with character preferences), player scores (to compare against their overall experience) and visualisation purposes (to e.g. depict a player struggling to climb a tree).</p>

			<h3>Process</h3>
			<p>Players were introduced to the process with a document introducing them briefly to the controls. Some character controls and abilities were omitted to test whether players would discover them without instruction. During the session, the players were directed by the observer to do the following:</p>
			
			<ul>
				<li><b>Start:</b> Half the players are requested to play the pigeon, and the other half to play the bunny.</li>
				<li><b>5 minutes in:</b> Players were asked to switch their character, i.e. play as the opposite character for the next five minutes.</li>
				<li><b>10 minutes in:</b> After equal time playing each character, players were explicitly permitted to play as either character for the remaining play time.</li>
			</ul>
			
			<p>The players were deliberately divided into these two timed groups in order to a) enable a balanced mixture of flying and ground characters, and b) reduce potential recall bias. In other words, using this strategy, the amount of players who started as the bunny and ended as the pigeon; and vice-versa were equal, cancelling out the potential bias for the first (or last) character remembered.</p>
			
			<h3>The questionnaire</h3>
			<h4>Character comparison</h4>
			<p>Each of the game's two characters had a set of Likert scales referring to particular experience-related qualities of each character. This enabled the observer to compare the mean popularity of the two. The following questions were asked:</p>
	
			<ul>
			<li>There were regular frustrations</li>
			<li>The character was easy to control</li>
			<li>The character was fun to control</li>
			<li>The character was enjoyable to play</li>
			</ul>

			<p>These were designed to quantify and contrast the differences in enjoyment and ease of control between the two characters. This would aid the designers in prioritising which character to improve.</p>
			
			<h4>Character ability check</h4>
			<p>The following binary-response questions were applied to test whether recipients knew about particular abilities. This was expected to provide a degree of understanding as to how intuitive (naturally-discovered) the controls were. The abilities addressed below were omitted from the introductory document.</p>
			<ul>
			<li>Did you prefer to fire powerful charged shots, or rapid uncharged shots? (Bunny)</li>
			<li>Were you aware that running charges your energy bar? (Be honest!)</li>
			<li>Did you realise that lighting your fuse gives you a speed boost? (Be honest!)</li>
			</ul>
			<p>The answers to these questions were simply "yes" or "no", with the exception of the first question, wherein the response specified "powerful charged shots" or "rapid uncharged shots". This was to maximise clarity, as there could have easily been confusion around which ability was being referred to.</p>
			
			<h4>Open questions</h4>
			<p>The following two questions were asked towards the end of the questionnaire.</p>
			<ul>
			<li>What was your favourite thing about this game?</li>
			<li>What was your least favourite thing about this game?</li>
			</ul>
			<p>These questions were intended to gain simplified, critical feedback from the game. To ascertain the importance of the issues, specific questions such as 'how did you feel about the character controls' were omitted. This is partly because responses to questions like that would likely elicit unusually critical and insightful responses: this is a known source of bias [3]. Instead, these much broader questions enabled the player to express the first things on their minds. While the results of these questions would not supply easily-quantifiable data applicable to a specific category, it encourages the player to reveal their strongest positive and negative opinions in a single, small-scope response.</p>
			<h4>General player character preferences</h4>
			<p>The following questions were intended to delve into players' gameplay and aesthetics preferences between characters, with a primary goal of finding a link between the two. They were asked in binary form, with the response being either "Static Bunny" or "Homing Pigeon".</p>
			<ul>
			<li>Which character was your favourite aesthetically?</li>
			<li>Which character was your favourite gameplay-wise?</li>
			<li>Which character was your favourite gameplay-wise, if it were designed perfectly?</li>
			</ul>
			<p>To marginally reduce bias, the order of characters were swapped for each character, discouraging them from selecting the same character each time as a result of question ordering (which can often influence questionnaire results [4]). The final question may cause some confusion, and in fact it may produce a level of bias, where some respondents may not want to look like they exclusively prefer one character, and so choose the other character. This should be considered in the results.</p>
			<h4>Preferences for number of players</h4>
			<p>Finally, a Likert-style question asked the following:</p>
			<ul>
			<li>How did you feel about the number of players?</li>
			</ul>
			<p>To prevent potential insight bias [3], the quesionnaire refrained from asking the respondents what specific number of players would be ideal. Instead, to focus on detecting a desire for more or less players, a Likert-style scale between 1 and 5 was added to let them express whether they wanted to see more or less players, where 1 was explicitly labelled "I wanted less players" and 5 was explicitly labelled "I wanted more players".</p>
			<p>In future surveys, this question could be repeated, with different player counts in each retake. This would allow the observers to triangulate the ideal number of players per gameplay session.</p>
			<h3>Sources</h3>
			<i>3. J. Metcalfe and D. Wiebe, "Intuition in insight and nonsight problem solving. Memory & cognition." in Memory & Cognition, June 1987, pp.238-246. </i><br />
			<i>4. B. C. Choi and A. W. Pak, “A Catalog of Biases in Questionnaires,” Preventing Chronic Disease, vol. 2, Dec. 2004</i>
		</section>
      </div>
      <footer>
        <h2>Louis F. - October 2018</h2>
      </footer>
    </div>
 	</body>
 </html>
